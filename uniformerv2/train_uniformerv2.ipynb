{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da73d178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 890M/890M [00:09<00:00, 99.2MiB/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 /workspace/thesis-ws/uniformerv2/extract_clip/extract_clip.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "20d41e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-26 12:24:56--  https://pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com/uniformerv2/k400/k400_k710_uniformerv2_l14_8x224.pyth\n",
      "Resolving pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com (pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com)... 106.14.228.87\n",
      "Connecting to pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com (pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com)|106.14.228.87|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1416533419 (1.3G) [application/octet-stream]\n",
      "Saving to: ‘k400_k710_uniformerv2_l14_8x224.pyth’\n",
      "\n",
      "k400_k710_uniformer 100%[===================>]   1.32G  12.2MB/s    in 2m 5s   \n",
      "\n",
      "2023-04-26 12:27:04 (10.8 MB/s) - ‘k400_k710_uniformerv2_l14_8x224.pyth’ saved [1416533419/1416533419]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pjlab-gvm-data.oss-cn-shanghai.aliyuncs.com/uniformerv2/k400/k400_k710_uniformerv2_l14_8x224.pyth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf8b45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir k400\n",
    "!mv k400_k710_uniformerv2_l14_8x224.pyth k400/k400_k710_uniformerv2_l14_8x224.pyth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a06b309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\t checkpoints\t   onstart.sh  submission.json\tvit_l14.pth\r\n",
      "Untitled1.ipynb  ego4d_data_annot  ports.log   thesis-ego4d\r\n",
      "Untitled2.ipynb  onstart.log\t   stdout.log  thesis-ws\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a294adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /workspace/thesis-ws\n",
    "git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "279a8e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build\n",
      "running build_py\n",
      "copying slowfast/models/uniformer.py -> build/lib/slowfast/models\n",
      "running develop\n",
      "running egg_info\n",
      "writing slowfast.egg-info/PKG-INFO\n",
      "writing dependency_links to slowfast.egg-info/dependency_links.txt\n",
      "writing requirements to slowfast.egg-info/requires.txt\n",
      "writing top-level names to slowfast.egg-info/top_level.txt\n",
      "reading manifest file 'slowfast.egg-info/SOURCES.txt'\n",
      "writing manifest file 'slowfast.egg-info/SOURCES.txt'\n",
      "running build_ext\n",
      "Creating /opt/conda/lib/python3.8/site-packages/slowfast.egg-link (link to .)\n",
      "slowfast 1.0 is already the active version in easy-install.pth\n",
      "\n",
      "Installed /workspace/thesis-ws/uniformerv2\n",
      "Processing dependencies for slowfast==1.0\n",
      "Searching for timm==0.8.19.dev0\n",
      "Best match: timm 0.8.19.dev0\n",
      "Processing timm-0.8.19.dev0-py3.8.egg\n",
      "timm 0.8.19.dev0 is already the active version in easy-install.pth\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages/timm-0.8.19.dev0-py3.8.egg\n",
      "Searching for tensorboard==2.12.2\n",
      "Best match: tensorboard 2.12.2\n",
      "Adding tensorboard 2.12.2 to easy-install.pth file\n",
      "Installing tensorboard script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for sklearn==0.0.post4\n",
      "Best match: sklearn 0.0.post4\n",
      "Processing sklearn-0.0.post4-py3.8.egg\n",
      "sklearn 0.0.post4 is already the active version in easy-install.pth\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages/sklearn-0.0.post4-py3.8.egg\n",
      "Searching for Pillow==9.0.1\n",
      "Best match: Pillow 9.0.1\n",
      "Adding Pillow 9.0.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for torchvision==0.12.0\n",
      "Best match: torchvision 0.12.0\n",
      "Adding torchvision 0.12.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for pandas==1.3.5\n",
      "Best match: pandas 1.3.5\n",
      "Adding pandas 1.3.5 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for opencv-python==4.7.0.72\n",
      "Best match: opencv-python 4.7.0.72\n",
      "Adding opencv-python 4.7.0.72 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for matplotlib==3.7.1\n",
      "Best match: matplotlib 3.7.1\n",
      "Adding matplotlib 3.7.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for psutil==5.9.0\n",
      "Best match: psutil 5.9.0\n",
      "Adding psutil 5.9.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for tqdm==4.62.3\n",
      "Best match: tqdm 4.62.3\n",
      "Adding tqdm 4.62.3 to easy-install.pth file\n",
      "Installing tqdm script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for simplejson==3.19.1\n",
      "Best match: simplejson 3.19.1\n",
      "Processing simplejson-3.19.1-py3.8.egg\n",
      "simplejson 3.19.1 is already the active version in easy-install.pth\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages/simplejson-3.19.1-py3.8.egg\n",
      "Searching for termcolor==2.3.0\n",
      "Best match: termcolor 2.3.0\n",
      "Adding termcolor 2.3.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for av==10.0.0\n",
      "Best match: av 10.0.0\n",
      "Adding av 10.0.0 to easy-install.pth file\n",
      "Installing pyav script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for PyYAML==6.0\n",
      "Best match: PyYAML 6.0\n",
      "Adding PyYAML 6.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for yacs==0.1.8\n",
      "Best match: yacs 0.1.8\n",
      "Adding yacs 0.1.8 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for torch==1.11.0\n",
      "Best match: torch 1.11.0\n",
      "Adding torch 1.11.0 to easy-install.pth file\n",
      "Installing convert-caffe2-to-onnx script to /opt/conda/bin\n",
      "Installing convert-onnx-to-caffe2 script to /opt/conda/bin\n",
      "Installing torchrun script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for safetensors==0.3.1\n",
      "Best match: safetensors 0.3.1\n",
      "Processing safetensors-0.3.1-py3.8-linux-x86_64.egg\n",
      "safetensors 0.3.1 is already the active version in easy-install.pth\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages/safetensors-0.3.1-py3.8-linux-x86_64.egg\n",
      "Searching for huggingface-hub==0.14.1\n",
      "Best match: huggingface-hub 0.14.1\n",
      "Processing huggingface_hub-0.14.1-py3.8.egg\n",
      "huggingface-hub 0.14.1 is already the active version in easy-install.pth\n",
      "Installing huggingface-cli script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages/huggingface_hub-0.14.1-py3.8.egg\n",
      "Searching for requests==2.28.2\n",
      "Best match: requests 2.28.2\n",
      "Adding requests 2.28.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for absl-py==1.4.0\n",
      "Best match: absl-py 1.4.0\n",
      "Adding absl-py 1.4.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for google-auth-oauthlib==1.0.0\n",
      "Best match: google-auth-oauthlib 1.0.0\n",
      "Adding google-auth-oauthlib 1.0.0 to easy-install.pth file\n",
      "Installing google-oauthlib-tool script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for Werkzeug==2.3.0\n",
      "Best match: Werkzeug 2.3.0\n",
      "Adding Werkzeug 2.3.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for protobuf==4.22.3\n",
      "Best match: protobuf 4.22.3\n",
      "Adding protobuf 4.22.3 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for tensorboard-plugin-wit==1.8.1\n",
      "Best match: tensorboard-plugin-wit 1.8.1\n",
      "Adding tensorboard-plugin-wit 1.8.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for numpy==1.24.3\n",
      "Best match: numpy 1.24.3\n",
      "Processing numpy-1.24.3-py3.8-linux-x86_64.egg\n",
      "numpy 1.24.3 is already the active version in easy-install.pth\n",
      "Installing f2py script to /opt/conda/bin\n",
      "Installing f2py3 script to /opt/conda/bin\n",
      "Installing f2py3.8 script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages/numpy-1.24.3-py3.8-linux-x86_64.egg\n",
      "Searching for tensorboard-data-server==0.7.0\n",
      "Best match: tensorboard-data-server 0.7.0\n",
      "Adding tensorboard-data-server 0.7.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for wheel==0.40.0\n",
      "Best match: wheel 0.40.0\n",
      "Processing wheel-0.40.0-py3.8.egg\n",
      "wheel 0.40.0 is already the active version in easy-install.pth\n",
      "Installing wheel script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages/wheel-0.40.0-py3.8.egg\n",
      "Searching for setuptools==58.0.4\n",
      "Best match: setuptools 58.0.4\n",
      "Adding setuptools 58.0.4 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for google-auth==2.17.3\n",
      "Best match: google-auth 2.17.3\n",
      "Adding google-auth 2.17.3 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for grpcio==1.54.0\n",
      "Best match: grpcio 1.54.0\n",
      "Adding grpcio 1.54.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for Markdown==3.4.3\n",
      "Best match: Markdown 3.4.3\n",
      "Adding Markdown 3.4.3 to easy-install.pth file\n",
      "Installing markdown_py script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for typing-extensions==3.10.0.2\n",
      "Best match: typing-extensions 3.10.0.2\n",
      "Adding typing-extensions 3.10.0.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for python-dateutil==2.8.2\n",
      "Best match: python-dateutil 2.8.2\n",
      "Adding python-dateutil 2.8.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for pytz==2023.3\n",
      "Best match: pytz 2023.3\n",
      "Processing pytz-2023.3-py3.8.egg\n",
      "pytz 2023.3 is already the active version in easy-install.pth\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages/pytz-2023.3-py3.8.egg\n",
      "Searching for packaging==23.1\n",
      "Best match: packaging 23.1\n",
      "Adding packaging 23.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for importlib-resources==5.12.0\n",
      "Best match: importlib-resources 5.12.0\n",
      "Adding importlib-resources 5.12.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for cycler==0.11.0\n",
      "Best match: cycler 0.11.0\n",
      "Adding cycler 0.11.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for contourpy==1.0.7\n",
      "Best match: contourpy 1.0.7\n",
      "Adding contourpy 1.0.7 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for kiwisolver==1.4.4\n",
      "Best match: kiwisolver 1.4.4\n",
      "Adding kiwisolver 1.4.4 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for fonttools==4.39.3\n",
      "Best match: fonttools 4.39.3\n",
      "Adding fonttools 4.39.3 to easy-install.pth file\n",
      "Installing fonttools script to /opt/conda/bin\n",
      "Installing pyftmerge script to /opt/conda/bin\n",
      "Installing pyftsubset script to /opt/conda/bin\n",
      "Installing ttx script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for pyparsing==3.0.9\n",
      "Best match: pyparsing 3.0.9\n",
      "Adding pyparsing 3.0.9 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for fsspec==2023.4.0\n",
      "Best match: fsspec 2023.4.0\n",
      "Adding fsspec 2023.4.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for filelock==3.4.2\n",
      "Best match: filelock 3.4.2\n",
      "Adding filelock 3.4.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for urllib3==1.26.15\n",
      "Best match: urllib3 1.26.15\n",
      "Processing urllib3-1.26.15-py3.8.egg\n",
      "urllib3 1.26.15 is already the active version in easy-install.pth\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages/urllib3-1.26.15-py3.8.egg\n",
      "Searching for certifi==2021.10.8\n",
      "Best match: certifi 2021.10.8\n",
      "Adding certifi 2021.10.8 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for charset-normalizer==2.0.4\n",
      "Best match: charset-normalizer 2.0.4\n",
      "Adding charset-normalizer 2.0.4 to easy-install.pth file\n",
      "Installing normalizer script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for idna==3.3\n",
      "Best match: idna 3.3\n",
      "Adding idna 3.3 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for requests-oauthlib==1.3.1\n",
      "Best match: requests-oauthlib 1.3.1\n",
      "Adding requests-oauthlib 1.3.1 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for MarkupSafe==2.1.2\n",
      "Best match: MarkupSafe 2.1.2\n",
      "Adding MarkupSafe 2.1.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for six==1.16.0\n",
      "Best match: six 1.16.0\n",
      "Adding six 1.16.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for cachetools==5.3.0\n",
      "Best match: cachetools 5.3.0\n",
      "Adding cachetools 5.3.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for rsa==4.9\n",
      "Best match: rsa 4.9\n",
      "Adding rsa 4.9 to easy-install.pth file\n",
      "Installing pyrsa-decrypt script to /opt/conda/bin\n",
      "Installing pyrsa-encrypt script to /opt/conda/bin\n",
      "Installing pyrsa-keygen script to /opt/conda/bin\n",
      "Installing pyrsa-priv2pub script to /opt/conda/bin\n",
      "Installing pyrsa-sign script to /opt/conda/bin\n",
      "Installing pyrsa-verify script to /opt/conda/bin\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for pyasn1-modules==0.3.0\n",
      "Best match: pyasn1-modules 0.3.0\n",
      "Adding pyasn1-modules 0.3.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for importlib-metadata==6.6.0\n",
      "Best match: importlib-metadata 6.6.0\n",
      "Adding importlib-metadata 6.6.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for zipp==3.15.0\n",
      "Best match: zipp 3.15.0\n",
      "Adding zipp 3.15.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for oauthlib==3.2.2\n",
      "Best match: oauthlib 3.2.2\n",
      "Adding oauthlib 3.2.2 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Searching for pyasn1==0.5.0\n",
      "Best match: pyasn1 0.5.0\n",
      "Adding pyasn1 0.5.0 to easy-install.pth file\n",
      "\n",
      "Using /opt/conda/lib/python3.8/site-packages\n",
      "Finished processing dependencies for slowfast==1.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /workspace/thesis-ws/uniformerv2\n",
    "python3 setup.py build develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc633019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/26 17:30:59][INFO] train_net.py: 411: Train with config:\r\n",
      "[04/26 17:30:59][INFO] train_net.py: 412: {'AUG': {'AA_TYPE': 'rand-m7-n4-mstd0.5-inc1',\r\n",
      "         'COLOR_JITTER': 0.4,\r\n",
      "         'ENABLE': True,\r\n",
      "         'INTERPOLATION': 'bicubic',\r\n",
      "         'NUM_SAMPLE': 1,\r\n",
      "         'RE_COUNT': 1,\r\n",
      "         'RE_MODE': 'pixel',\r\n",
      "         'RE_PROB': 0.0,\r\n",
      "         'RE_SPLIT': False},\r\n",
      " 'AVA': {'ANNOTATION_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',\r\n",
      "         'BGR': False,\r\n",
      "         'DETECTION_SCORE_THRESH': 0.9,\r\n",
      "         'EXCLUSION_FILE': 'ava_val_excluded_timestamps_v2.2.csv',\r\n",
      "         'FRAME_DIR': '/mnt/fair-flash3-east/ava_trainval_frames.img/',\r\n",
      "         'FRAME_LIST_DIR': '/mnt/vol/gfsai-flash3-east/ai-group/users/haoqifan/ava/frame_list/',\r\n",
      "         'FULL_TEST_ON_VAL': False,\r\n",
      "         'GROUNDTRUTH_FILE': 'ava_val_v2.2.csv',\r\n",
      "         'IMG_PROC_BACKEND': 'cv2',\r\n",
      "         'LABEL_MAP_FILE': 'ava_action_list_v2.2_for_activitynet_2019.pbtxt',\r\n",
      "         'TEST_FORCE_FLIP': False,\r\n",
      "         'TEST_LISTS': ['val.csv'],\r\n",
      "         'TEST_PREDICT_BOX_LISTS': ['ava_val_predicted_boxes.csv'],\r\n",
      "         'TRAIN_GT_BOX_LISTS': ['ava_train_v2.2.csv'],\r\n",
      "         'TRAIN_LISTS': ['train.csv'],\r\n",
      "         'TRAIN_PCA_JITTER_ONLY': True,\r\n",
      "         'TRAIN_PREDICT_BOX_LISTS': [],\r\n",
      "         'TRAIN_USE_COLOR_AUGMENTATION': False},\r\n",
      " 'BENCHMARK': CfgNode({'NUM_EPOCHS': 5, 'LOG_PERIOD': 100, 'SHUFFLE': True}),\r\n",
      " 'BN': {'NORM_TYPE': 'batchnorm',\r\n",
      "        'NUM_BATCHES_PRECISE': 200,\r\n",
      "        'NUM_SPLITS': 1,\r\n",
      "        'NUM_SYNC_DEVICES': 1,\r\n",
      "        'USE_PRECISE_STATS': False,\r\n",
      "        'WEIGHT_DECAY': 0.0},\r\n",
      " 'DATA': {'DECODING_BACKEND': 'pyav',\r\n",
      "          'ENSEMBLE_METHOD': 'sum',\r\n",
      "          'EXTRA_PATH_TO_DATA_DIR': '',\r\n",
      "          'IMAGE_TEMPLATE': '{:05d}.jpg',\r\n",
      "          'INPUT_CHANNEL_NUM': [3],\r\n",
      "          'INV_UNIFORM_SAMPLE': False,\r\n",
      "          'LABEL_PATH_TEMPLATE': 'somesomev1_rgb_{}_split.txt',\r\n",
      "          'MC': False,\r\n",
      "          'MEAN': [0.45, 0.45, 0.45],\r\n",
      "          'MULTI_LABEL': False,\r\n",
      "          'NUM_FRAMES': 8,\r\n",
      "          'PATH_LABEL_SEPARATOR': ' ',\r\n",
      "          'PATH_PREFIX': '',\r\n",
      "          'PATH_PREFIX_LIST': [''],\r\n",
      "          'PATH_TO_DATA_DIR': '/workspace/ego4d_data_annot',\r\n",
      "          'PATH_TO_DATA_DIR_LIST': [''],\r\n",
      "          'PATH_TO_PRELOAD_IMDB': '',\r\n",
      "          'RANDOM_FLIP': True,\r\n",
      "          'REVERSE_INPUT_CHANNEL': False,\r\n",
      "          'SAMPLING_RATE': 8,\r\n",
      "          'STD': [0.225, 0.225, 0.225],\r\n",
      "          'TARGET_FPS': 30,\r\n",
      "          'TEST_CROP_SIZE': 224,\r\n",
      "          'TRAIN_CROP_SIZE': 224,\r\n",
      "          'TRAIN_JITTER_ASPECT_RELATIVE': [],\r\n",
      "          'TRAIN_JITTER_MOTION_SHIFT': False,\r\n",
      "          'TRAIN_JITTER_SCALES': [256, 320],\r\n",
      "          'TRAIN_JITTER_SCALES_RELATIVE': [],\r\n",
      "          'TRAIN_PCA_EIGVAL': [0.225, 0.224, 0.229],\r\n",
      "          'TRAIN_PCA_EIGVEC': [[-0.5675, 0.7192, 0.4009],\r\n",
      "                               [-0.5808, -0.0045, -0.814],\r\n",
      "                               [-0.5836, -0.6948, 0.4203]],\r\n",
      "          'USE_OFFSET_SAMPLING': False},\r\n",
      " 'DATA_LOADER': {'ENABLE_MULTI_THREAD_DECODE': False,\r\n",
      "                 'NUM_WORKERS': 8,\r\n",
      "                 'PIN_MEMORY': True},\r\n",
      " 'DEMO': {'BUFFER_SIZE': 0,\r\n",
      "          'CLIP_VIS_SIZE': 10,\r\n",
      "          'COMMON_CLASS_NAMES': ['watch (a person)',\r\n",
      "                                 'talk to (e.g., self, a person, a group)',\r\n",
      "                                 'listen to (a person)',\r\n",
      "                                 'touch (an object)',\r\n",
      "                                 'carry/hold (an object)',\r\n",
      "                                 'walk',\r\n",
      "                                 'sit',\r\n",
      "                                 'lie/sleep',\r\n",
      "                                 'bend/bow (at the waist)'],\r\n",
      "          'COMMON_CLASS_THRES': 0.7,\r\n",
      "          'DETECTRON2_CFG': 'COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml',\r\n",
      "          'DETECTRON2_THRESH': 0.9,\r\n",
      "          'DETECTRON2_WEIGHTS': 'detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl',\r\n",
      "          'DISPLAY_HEIGHT': 0,\r\n",
      "          'DISPLAY_WIDTH': 0,\r\n",
      "          'ENABLE': False,\r\n",
      "          'FPS': 30,\r\n",
      "          'GT_BOXES': '',\r\n",
      "          'INPUT_FORMAT': 'BGR',\r\n",
      "          'INPUT_VIDEO': '',\r\n",
      "          'LABEL_FILE_PATH': '',\r\n",
      "          'NUM_CLIPS_SKIP': 0,\r\n",
      "          'NUM_VIS_INSTANCES': 2,\r\n",
      "          'OUTPUT_FILE': '',\r\n",
      "          'OUTPUT_FPS': -1,\r\n",
      "          'PREDS_BOXES': '',\r\n",
      "          'SLOWMO': 1,\r\n",
      "          'STARTING_SECOND': 900,\r\n",
      "          'THREAD_ENABLE': False,\r\n",
      "          'UNCOMMON_CLASS_THRES': 0.3,\r\n",
      "          'VIS_MODE': 'thres',\r\n",
      "          'WEBCAM': -1},\r\n",
      " 'DETECTION': {'ALIGNED': True,\r\n",
      "               'ENABLE': False,\r\n",
      "               'ROI_XFORM_RESOLUTION': 7,\r\n",
      "               'SPATIAL_SCALE_FACTOR': 16},\r\n",
      " 'DIST_BACKEND': 'nccl',\r\n",
      " 'LOG_MODEL_INFO': True,\r\n",
      " 'LOG_PERIOD': 10,\r\n",
      " 'MIXUP': {'ALPHA': 0.8,\r\n",
      "           'CUTMIX_ALPHA': 1.0,\r\n",
      "           'ENABLE': False,\r\n",
      "           'LABEL_SMOOTH_VALUE': 0.1,\r\n",
      "           'PROB': 1.0,\r\n",
      "           'SWITCH_PROB': 0.5},\r\n",
      " 'MODEL': {'ARCH': 'uniformerv2',\r\n",
      "           'CHECKPOINT_NUM': [1],\r\n",
      "           'DROPCONNECT_RATE': 0.0,\r\n",
      "           'DROPOUT_RATE': 0.5,\r\n",
      "           'EMA_DECAY': 0.9999,\r\n",
      "           'EMA_EPOCH': -1,\r\n",
      "           'FC_INIT_STD': 0.01,\r\n",
      "           'HEAD_ACT': 'softmax',\r\n",
      "           'LOSS_FUNC': 'cross_entropy',\r\n",
      "           'MODEL_NAME': 'Uniformerv2',\r\n",
      "           'MULTI_PATHWAY_ARCH': ['slowfast'],\r\n",
      "           'NUM_CLASSES': 20,\r\n",
      "           'NUM_CLASSES_LIST': [400, 600, 700],\r\n",
      "           'SINGLE_PATHWAY_ARCH': ['2d',\r\n",
      "                                   'c2d',\r\n",
      "                                   'i3d',\r\n",
      "                                   'slow',\r\n",
      "                                   'x3d',\r\n",
      "                                   'mvit',\r\n",
      "                                   'uniformer',\r\n",
      "                                   'uniformerv2'],\r\n",
      "           'USE_CHECKPOINT': True},\r\n",
      " 'MULTIGRID': {'BN_BASE_SIZE': 8,\r\n",
      "               'DEFAULT_B': 0,\r\n",
      "               'DEFAULT_S': 0,\r\n",
      "               'DEFAULT_T': 0,\r\n",
      "               'EPOCH_FACTOR': 1.5,\r\n",
      "               'EVAL_FREQ': 3,\r\n",
      "               'LONG_CYCLE': False,\r\n",
      "               'LONG_CYCLE_FACTORS': [(0.25, 0.7071067811865476),\r\n",
      "                                      (0.5, 0.7071067811865476),\r\n",
      "                                      (0.5, 1),\r\n",
      "                                      (1, 1)],\r\n",
      "               'LONG_CYCLE_SAMPLING_RATE': 0,\r\n",
      "               'SHORT_CYCLE': False,\r\n",
      "               'SHORT_CYCLE_FACTORS': [0.5, 0.7071067811865476]},\r\n",
      " 'MVIT': {'CLS_EMBED_ON': True,\r\n",
      "          'DEPTH': 16,\r\n",
      "          'DIM_MUL': [],\r\n",
      "          'DROPOUT_RATE': 0.0,\r\n",
      "          'DROPPATH_RATE': 0.1,\r\n",
      "          'EMBED_DIM': 96,\r\n",
      "          'HEAD_MUL': [],\r\n",
      "          'MLP_RATIO': 4.0,\r\n",
      "          'MODE': 'conv',\r\n",
      "          'NORM': 'layernorm',\r\n",
      "          'NORM_STEM': False,\r\n",
      "          'NUM_HEADS': 1,\r\n",
      "          'PATCH_2D': False,\r\n",
      "          'PATCH_KERNEL': [3, 7, 7],\r\n",
      "          'PATCH_PADDING': [2, 4, 4],\r\n",
      "          'PATCH_STRIDE': [2, 4, 4],\r\n",
      "          'POOL_KVQ_KERNEL': None,\r\n",
      "          'POOL_KV_STRIDE': [],\r\n",
      "          'POOL_Q_STRIDE': [],\r\n",
      "          'QKV_BIAS': True,\r\n",
      "          'SEP_POS_EMBED': False,\r\n",
      "          'ZERO_DECAY_POS_CLS': True},\r\n",
      " 'NONLOCAL': {'GROUP': [[1], [1], [1], [1]],\r\n",
      "              'INSTANTIATION': 'dot_product',\r\n",
      "              'LOCATION': [[[]], [[]], [[]], [[]]],\r\n",
      "              'POOL': [[[1, 2, 2], [1, 2, 2]],\r\n",
      "                       [[1, 2, 2], [1, 2, 2]],\r\n",
      "                       [[1, 2, 2], [1, 2, 2]],\r\n",
      "                       [[1, 2, 2], [1, 2, 2]]]},\r\n",
      " 'NUM_GPUS': 1,\r\n",
      " 'NUM_SHARDS': 1,\r\n",
      " 'OUTPUT_DIR': '.',\r\n",
      " 'RESNET': {'DEPTH': 50,\r\n",
      "            'INPLACE_RELU': True,\r\n",
      "            'NUM_BLOCK_TEMP_KERNEL': [[3], [4], [6], [3]],\r\n",
      "            'NUM_GROUPS': 1,\r\n",
      "            'SPATIAL_DILATIONS': [[1], [1], [1], [1]],\r\n",
      "            'SPATIAL_STRIDES': [[1], [2], [2], [2]],\r\n",
      "            'STRIDE_1X1': False,\r\n",
      "            'TRANS_FUNC': 'bottleneck_transform',\r\n",
      "            'WIDTH_PER_GROUP': 64,\r\n",
      "            'ZERO_INIT_FINAL_BN': False},\r\n",
      " 'RNG_SEED': 0,\r\n",
      " 'SHARD_ID': 0,\r\n",
      " 'SLOWFAST': {'ALPHA': 8,\r\n",
      "              'BETA_INV': 8,\r\n",
      "              'FUSION_CONV_CHANNEL_RATIO': 2,\r\n",
      "              'FUSION_KERNEL_SZ': 5},\r\n",
      " 'SOLVER': {'BACKBONE_LR_RATIO': 0.1,\r\n",
      "            'BASE_LR': 0.0004,\r\n",
      "            'BASE_LR_SCALE_NUM_SHARDS': True,\r\n",
      "            'CLIP_GRADIENT': 20,\r\n",
      "            'COSINE_AFTER_WARMUP': True,\r\n",
      "            'COSINE_END_LR': 1e-06,\r\n",
      "            'DAMPENING': 0.0,\r\n",
      "            'GAMMA': 0.1,\r\n",
      "            'LRS': [],\r\n",
      "            'LR_POLICY': 'cosine',\r\n",
      "            'MAX_EPOCH': 50,\r\n",
      "            'MOMENTUM': 0.9,\r\n",
      "            'NESTEROV': True,\r\n",
      "            'OPTIMIZING_METHOD': 'adamw',\r\n",
      "            'SPECIAL_LIST': [],\r\n",
      "            'SPECIAL_RATIO': 1.0,\r\n",
      "            'STEPS': [],\r\n",
      "            'STEP_SIZE': 1,\r\n",
      "            'WARMUP_EPOCHS': 0.0,\r\n",
      "            'WARMUP_FACTOR': 0.1,\r\n",
      "            'WARMUP_START_LR': 1e-06,\r\n",
      "            'WEIGHT_DECAY': 0.05,\r\n",
      "            'ZERO_WD_1D_PARAM': True},\r\n",
      " 'TENSORBOARD': {'CATEGORIES_PATH': '',\r\n",
      "                 'CLASS_NAMES_PATH': '',\r\n",
      "                 'CONFUSION_MATRIX': {'ENABLE': False,\r\n",
      "                                      'FIGSIZE': [8, 8],\r\n",
      "                                      'SUBSET_PATH': ''},\r\n",
      "                 'ENABLE': False,\r\n",
      "                 'HISTOGRAM': {'ENABLE': False,\r\n",
      "                               'FIGSIZE': [8, 8],\r\n",
      "                               'SUBSET_PATH': '',\r\n",
      "                               'TOPK': 10},\r\n",
      "                 'LOG_DIR': '',\r\n",
      "                 'MODEL_VIS': {'ACTIVATIONS': False,\r\n",
      "                               'COLORMAP': 'Pastel2',\r\n",
      "                               'ENABLE': False,\r\n",
      "                               'GRAD_CAM': {'COLORMAP': 'viridis',\r\n",
      "                                            'ENABLE': True,\r\n",
      "                                            'LAYER_LIST': [],\r\n",
      "                                            'USE_TRUE_LABEL': False},\r\n",
      "                               'INPUT_VIDEO': False,\r\n",
      "                               'LAYER_LIST': [],\r\n",
      "                               'MODEL_WEIGHTS': False,\r\n",
      "                               'TOPK_PREDS': 1},\r\n",
      "                 'PREDICTIONS_PATH': '',\r\n",
      "                 'WRONG_PRED_VIS': {'ENABLE': False,\r\n",
      "                                    'SUBSET_PATH': '',\r\n",
      "                                    'TAG': 'Incorrectly classified videos.'}},\r\n",
      " 'TEST': {'ADD_SOFTMAX': True,\r\n",
      "          'BATCH_SIZE': 256,\r\n",
      "          'CHECKPOINT_FILE_PATH': '',\r\n",
      "          'CHECKPOINT_TYPE': 'pytorch',\r\n",
      "          'DATASET': 'ant',\r\n",
      "          'ENABLE': True,\r\n",
      "          'INTERVAL': 2000,\r\n",
      "          'NUM_ENSEMBLE_VIEWS': 1,\r\n",
      "          'NUM_SPATIAL_CROPS': 1,\r\n",
      "          'SAVE_RESULTS_PATH': '',\r\n",
      "          'TEST_BEST': False},\r\n",
      " 'TRAIN': {'AUTO_RESUME': True,\r\n",
      "           'BATCH_SIZE': 8,\r\n",
      "           'CHECKPOINT_CLEAR_NAME_PATTERN': (),\r\n",
      "           'CHECKPOINT_EPOCH_RESET': False,\r\n",
      "           'CHECKPOINT_FILE_PATH': '',\r\n",
      "           'CHECKPOINT_INFLATE': False,\r\n",
      "           'CHECKPOINT_PERIOD': 5,\r\n",
      "           'CHECKPOINT_TYPE': 'pytorch',\r\n",
      "           'DATASET': 'ego4dhand',\r\n",
      "           'ENABLE': True,\r\n",
      "           'EVAL_PERIOD': 1,\r\n",
      "           'SAVE_LATEST': False},\r\n",
      " 'UNIFORMER': {'ADD_MLP': True,\r\n",
      "               'ATTENTION_DROPOUT_RATE': 0,\r\n",
      "               'DEPTH': [3, 4, 8, 3],\r\n",
      "               'DPE': True,\r\n",
      "               'DROPOUT_RATE': 0,\r\n",
      "               'DROP_DEPTH_RATE': 0.1,\r\n",
      "               'EMBED_DIM': [64, 128, 320, 512],\r\n",
      "               'HEAD_DIM': 64,\r\n",
      "               'INIT_VALUE': 1.0,\r\n",
      "               'KS': 5,\r\n",
      "               'MBCONV': False,\r\n",
      "               'MLP_RATIO': [4.0, 4.0, 4.0, 4.0],\r\n",
      "               'NUM_HEADS': [1, 2, 5, 8],\r\n",
      "               'PRETRAIN_NAME': None,\r\n",
      "               'PRUNE_RATIO': [[],\r\n",
      "                               [],\r\n",
      "                               [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\r\n",
      "                               [0.5, 0.5, 0.5]],\r\n",
      "               'QKV_BIAS': True,\r\n",
      "               'QKV_SCALE': None,\r\n",
      "               'RATIO': 1,\r\n",
      "               'REPRESENTATION_SIZE': None,\r\n",
      "               'SPLIT': False,\r\n",
      "               'STAGE_TYPE': [0, 0, 1, 1],\r\n",
      "               'STD': False,\r\n",
      "               'TAU': 3,\r\n",
      "               'TRADE_OFF': [[],\r\n",
      "                             [],\r\n",
      "                             [1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\r\n",
      "                             [0.5, 0.5, 0.5]]},\r\n",
      " 'UNIFORMERV2': {'BACKBONE': 'uniformerv2_l14',\r\n",
      "                 'BACKBONE_DROP_PATH_RATE': 0.2,\r\n",
      "                 'CLS_DROPOUT': 0.5,\r\n",
      "                 'DELETE_SPECIAL_HEAD': True,\r\n",
      "                 'DOUBLE_LMHRA': True,\r\n",
      "                 'DROP_PATH_RATE': 0.4,\r\n",
      "                 'DW_REDUCTION': 1.5,\r\n",
      "                 'FROZEN': False,\r\n",
      "                 'MLP_DROPOUT': [0.5, 0.5, 0.5, 0.5],\r\n",
      "                 'MLP_FACTOR': 4.0,\r\n",
      "                 'NO_LMHRA': True,\r\n",
      "                 'N_DIM': 1024,\r\n",
      "                 'N_HEAD': 16,\r\n",
      "                 'N_LAYERS': 4,\r\n",
      "                 'PRETRAIN': 'k400/k400_k710_uniformerv2_l14_8x224.pyth',\r\n",
      "                 'RETURN_LIST': [20, 21, 22, 23],\r\n",
      "                 'TEMPORAL_DOWNSAMPLE': False},\r\n",
      " 'VIP': {'ATTENTION_DROPOUT_RATE': 0,\r\n",
      "         'DROP_DEPTH_RATE': 0.1,\r\n",
      "         'EMBED_DIMS': [192, 384, 384, 384],\r\n",
      "         'LAYERS': [4, 3, 8, 3],\r\n",
      "         'MLP_RATIOS': [3, 3, 3, 3],\r\n",
      "         'PATCH_SIZE': 7,\r\n",
      "         'PRETRAIN_NAME': None,\r\n",
      "         'QKV_BIAS': True,\r\n",
      "         'QKV_SCALE': None,\r\n",
      "         'SEGMENT_DIM': [32, 16, 16, 16],\r\n",
      "         'ST_TYPE': 'st_skip',\r\n",
      "         'TRANSITIONS': [True, False, False, False],\r\n",
      "         'T_STRIDE': 1},\r\n",
      " 'X3D': {'BN_LIN5': False,\r\n",
      "         'BOTTLENECK_FACTOR': 1.0,\r\n",
      "         'CHANNELWISE_3x3x3': True,\r\n",
      "         'DEPTH_FACTOR': 1.0,\r\n",
      "         'DIM_C1': 12,\r\n",
      "         'DIM_C5': 2048,\r\n",
      "         'SCALE_RES2': False,\r\n",
      "         'WIDTH_FACTOR': 1.0}}\r\n",
      "[04/26 17:30:59][INFO] uniformerv2_model.py:  72: Drop path rate: 0.0\n",
      "[04/26 17:30:59][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:30:59][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.008695652708411217\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.017391305416822433\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.02608695812523365\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.03478261083364487\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.04347826540470123\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.0521739162504673\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.06086956709623337\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.06956522166728973\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.0782608762383461\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.08695653080940247\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.09565217792987823\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.1043478325009346\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  72: Drop path rate: 0.11304348707199097\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:00][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.12173913419246674\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.1304347813129425\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.13913042843341827\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.14782609045505524\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.156521737575531\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.16521739959716797\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.17391304671764374\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.1826086938381195\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.19130435585975647\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  72: Drop path rate: 0.20000000298023224\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  76: No L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py:  77: Double L_MHRA: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py: 214: Use checkpoint: True\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py: 215: Checkpoint number: [1]\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py: 140: Drop path rate: 0.0\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py: 140: Drop path rate: 0.13333334028720856\n",
      "[04/26 17:31:01][INFO] uniformerv2_model.py: 140: Drop path rate: 0.2666666507720947\n",
      "[04/26 17:31:02][INFO] uniformerv2_model.py: 140: Drop path rate: 0.4000000059604645\n",
      "[04/26 17:31:02][INFO] uniformerv2_model.py: 444: load pretrained weights\n",
      "[04/26 17:31:02][INFO] uniformerv2_model.py: 354: Inflate: conv1.weight, torch.Size([1024, 3, 14, 14]) => torch.Size([1024, 3, 1, 14, 14])\n",
      "[04/26 17:31:02][INFO] uniformerv2_model.py: 335: Init center: True\n",
      "[04/26 17:31:02][INFO] uniformerv2.py:  68: load model from k400/k400_k710_uniformerv2_l14_8x224.pyth\n",
      "[04/26 17:31:03][INFO] uniformerv2.py:  71: Delete FC\n",
      "[04/26 17:31:05][INFO] misc.py: 183: Model:\n",
      "Uniformerv2(\n",
      "  (backbone): VisionTransformer(\n",
      "    (conv1): Conv3d(3, 1024, kernel_size=(1, 14, 14), stride=(1, 14, 14), bias=False)\n",
      "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (transformer): Transformer(\n",
      "      (resblocks): ModuleList(\n",
      "        (0): ResidualAttentionBlock(\n",
      "          (drop_path): Identity()\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.009)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.017)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.026)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.035)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.043)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.052)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.061)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.070)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.078)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.087)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.096)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (12): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.104)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (13): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.113)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (14): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.122)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (15): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.130)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (16): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.139)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (17): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.148)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (18): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.157)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (19): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.165)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (20): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.174)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (21): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.183)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (22): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.191)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (23): ResidualAttentionBlock(\n",
      "          (drop_path): DropPath(drop_prob=0.200)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (dpe): ModuleList(\n",
      "        (0): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024)\n",
      "        (1): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024)\n",
      "        (2): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024)\n",
      "        (3): Conv3d(1024, 1024, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1024)\n",
      "      )\n",
      "      (dec): ModuleList(\n",
      "        (0): Extractor(\n",
      "          (drop_path): Identity()\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (ln_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Extractor(\n",
      "          (drop_path): DropPath(drop_prob=0.133)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (ln_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): Extractor(\n",
      "          (drop_path): DropPath(drop_prob=0.267)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (ln_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): Extractor(\n",
      "          (drop_path): DropPath(drop_prob=0.400)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): QuickGELU()\n",
      "            (dropout): Dropout(p=0.5, inplace=False)\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (ln_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (proj): Sequential(\n",
      "        (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (1): Dropout(p=0.5, inplace=False)\n",
      "        (2): Linear(in_features=1024, out_features=20, bias=True)\n",
      "      )\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[04/26 17:31:05][INFO] misc.py: 184: Params: 353,710,100\n",
      "[04/26 17:31:05][INFO] misc.py: 185: Mem: 1.3183560371398926 MB\n",
      "/workspace/thesis-ws/uniformerv2/slowfast/models/uniformerv2_model.py:247: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  N = NT // T_down\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::mul encountered 127 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::add encountered 75 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::div encountered 51 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::repeat encountered 1 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator prim::PythonOp.CheckpointFunction encountered 2 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::softmax encountered 27 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::sigmoid encountered 28 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::clone encountered 8 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::sub encountered 4 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::numpy_T encountered 12 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::neg encountered 16 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::mean encountered 1 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 499: Unsupported operator aten::rsub encountered 1 time(s)\n",
      "[04/26 17:31:06][WARNING] jit_analysis.py: 511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "backbone.transformer.dec.1.drop_path, backbone.transformer.dec.2.drop_path, backbone.transformer.dec.3.drop_path, backbone.transformer.resblocks.0.attn, backbone.transformer.resblocks.0.attn.out_proj, backbone.transformer.resblocks.0.mlp, backbone.transformer.resblocks.0.mlp.c_fc, backbone.transformer.resblocks.0.mlp.c_proj, backbone.transformer.resblocks.0.mlp.gelu, backbone.transformer.resblocks.1.attn.out_proj, backbone.transformer.resblocks.1.drop_path, backbone.transformer.resblocks.10.attn.out_proj, backbone.transformer.resblocks.10.drop_path, backbone.transformer.resblocks.11.attn.out_proj, backbone.transformer.resblocks.11.drop_path, backbone.transformer.resblocks.12.attn.out_proj, backbone.transformer.resblocks.12.drop_path, backbone.transformer.resblocks.13.attn.out_proj, backbone.transformer.resblocks.13.drop_path, backbone.transformer.resblocks.14.attn.out_proj, backbone.transformer.resblocks.14.drop_path, backbone.transformer.resblocks.15.attn.out_proj, backbone.transformer.resblocks.15.drop_path, backbone.transformer.resblocks.16.attn.out_proj, backbone.transformer.resblocks.16.drop_path, backbone.transformer.resblocks.17.attn.out_proj, backbone.transformer.resblocks.17.drop_path, backbone.transformer.resblocks.18.attn.out_proj, backbone.transformer.resblocks.18.drop_path, backbone.transformer.resblocks.19.attn.out_proj, backbone.transformer.resblocks.19.drop_path, backbone.transformer.resblocks.2.attn.out_proj, backbone.transformer.resblocks.2.drop_path, backbone.transformer.resblocks.20.attn.out_proj, backbone.transformer.resblocks.20.drop_path, backbone.transformer.resblocks.21.attn.out_proj, backbone.transformer.resblocks.21.drop_path, backbone.transformer.resblocks.22.attn.out_proj, backbone.transformer.resblocks.22.drop_path, backbone.transformer.resblocks.23.attn.out_proj, backbone.transformer.resblocks.23.drop_path, backbone.transformer.resblocks.3.attn.out_proj, backbone.transformer.resblocks.3.drop_path, backbone.transformer.resblocks.4.attn.out_proj, backbone.transformer.resblocks.4.drop_path, backbone.transformer.resblocks.5.attn.out_proj, backbone.transformer.resblocks.5.drop_path, backbone.transformer.resblocks.6.attn.out_proj, backbone.transformer.resblocks.6.drop_path, backbone.transformer.resblocks.7.attn.out_proj, backbone.transformer.resblocks.7.drop_path, backbone.transformer.resblocks.8.attn.out_proj, backbone.transformer.resblocks.8.drop_path, backbone.transformer.resblocks.9.attn.out_proj, backbone.transformer.resblocks.9.drop_path\n",
      "[04/26 17:31:06][INFO] misc.py: 186: Flops: 639.2334837760001 G\n",
      "/workspace/thesis-ws/uniformerv2/slowfast/models/uniformerv2_model.py:247: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  N = NT // T_down\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::mul encountered 127 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::add encountered 75 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::layer_norm encountered 62 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::div encountered 51 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::repeat encountered 1 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator prim::PythonOp.CheckpointFunction encountered 2 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::softmax encountered 27 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::sigmoid encountered 28 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::clone encountered 8 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::sub encountered 4 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::numpy_T encountered 12 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::neg encountered 16 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::mean encountered 1 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 499: Unsupported operator aten::rsub encountered 1 time(s)\n",
      "[04/26 17:31:07][WARNING] jit_analysis.py: 511: The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "backbone.transformer.dec.1.drop_path, backbone.transformer.dec.2.drop_path, backbone.transformer.dec.3.drop_path, backbone.transformer.resblocks.0.attn, backbone.transformer.resblocks.0.attn.out_proj, backbone.transformer.resblocks.0.mlp, backbone.transformer.resblocks.0.mlp.c_fc, backbone.transformer.resblocks.0.mlp.c_proj, backbone.transformer.resblocks.0.mlp.gelu, backbone.transformer.resblocks.1.attn.out_proj, backbone.transformer.resblocks.1.drop_path, backbone.transformer.resblocks.10.attn.out_proj, backbone.transformer.resblocks.10.drop_path, backbone.transformer.resblocks.11.attn.out_proj, backbone.transformer.resblocks.11.drop_path, backbone.transformer.resblocks.12.attn.out_proj, backbone.transformer.resblocks.12.drop_path, backbone.transformer.resblocks.13.attn.out_proj, backbone.transformer.resblocks.13.drop_path, backbone.transformer.resblocks.14.attn.out_proj, backbone.transformer.resblocks.14.drop_path, backbone.transformer.resblocks.15.attn.out_proj, backbone.transformer.resblocks.15.drop_path, backbone.transformer.resblocks.16.attn.out_proj, backbone.transformer.resblocks.16.drop_path, backbone.transformer.resblocks.17.attn.out_proj, backbone.transformer.resblocks.17.drop_path, backbone.transformer.resblocks.18.attn.out_proj, backbone.transformer.resblocks.18.drop_path, backbone.transformer.resblocks.19.attn.out_proj, backbone.transformer.resblocks.19.drop_path, backbone.transformer.resblocks.2.attn.out_proj, backbone.transformer.resblocks.2.drop_path, backbone.transformer.resblocks.20.attn.out_proj, backbone.transformer.resblocks.20.drop_path, backbone.transformer.resblocks.21.attn.out_proj, backbone.transformer.resblocks.21.drop_path, backbone.transformer.resblocks.22.attn.out_proj, backbone.transformer.resblocks.22.drop_path, backbone.transformer.resblocks.23.attn.out_proj, backbone.transformer.resblocks.23.drop_path, backbone.transformer.resblocks.3.attn.out_proj, backbone.transformer.resblocks.3.drop_path, backbone.transformer.resblocks.4.attn.out_proj, backbone.transformer.resblocks.4.drop_path, backbone.transformer.resblocks.5.attn.out_proj, backbone.transformer.resblocks.5.drop_path, backbone.transformer.resblocks.6.attn.out_proj, backbone.transformer.resblocks.6.drop_path, backbone.transformer.resblocks.7.attn.out_proj, backbone.transformer.resblocks.7.drop_path, backbone.transformer.resblocks.8.attn.out_proj, backbone.transformer.resblocks.8.drop_path, backbone.transformer.resblocks.9.attn.out_proj, backbone.transformer.resblocks.9.drop_path\n",
      "[04/26 17:31:07][INFO] misc.py: 191: Activations: 706.1702600000001 M\n",
      "[04/26 17:31:07][INFO] misc.py: 196: nvidia-smi\n",
      "Wed Apr 26 17:31:07 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:C1:00.0 Off |                  N/A |\n",
      "| 32%   48C    P2   133W / 350W |   9709MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n",
      "[04/26 17:31:07][INFO] optimizer.py:  71: bn 0, non bn 120, zero 243\n",
      "[04/26 17:31:07][INFO] ego4dhand.py:  76: Constructing Ego4D train...\n",
      "[04/26 17:31:09][INFO] ego4dhand.py: 194: Constructing Ego4D dataloader (size: 23260) from /workspace/ego4d_data_annot/annotations/fho_hands_train.json\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/thesis-ws/uniformerv2/tools/run_net.py\", line 44, in <module>\n",
      "    main()\n",
      "  File \"/workspace/thesis-ws/uniformerv2/tools/run_net.py\", line 25, in main\n",
      "    launch_job(cfg=cfg, init_method=args.init_method, func=train)\n",
      "  File \"/workspace/thesis-ws/uniformerv2/slowfast/utils/misc.py\", line 311, in launch_job\n",
      "    func(cfg=cfg)\n",
      "  File \"/workspace/thesis-ws/uniformerv2/tools/train_net.py\", line 429, in train\n",
      "    train_loader = loader.construct_loader(cfg, \"train\")\n",
      "  File \"/workspace/thesis-ws/uniformerv2/slowfast/datasets/loader.py\", line 147, in construct_loader\n",
      "    sampler = utils.create_sampler(dataset, shuffle, cfg)\n",
      "  File \"/workspace/thesis-ws/uniformerv2/slowfast/datasets/utils.py\", line 412, in create_sampler\n",
      "    sampler = DistributedSampler(dataset) if cfg.NUM_GPUS >= 1 else None\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/utils/data/distributed.py\", line 66, in __init__\n",
      "    num_replicas = dist.get_world_size()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py\", line 867, in get_world_size\n",
      "    return _get_group_size(group)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py\", line 325, in _get_group_size\n",
      "    default_pg = _get_default_group()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py\", line 429, in _get_default_group\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Default process group has not been initialized, please make sure to call init_process_group.\n"
     ]
    }
   ],
   "source": [
    "!python3 /workspace/thesis-ws/uniformerv2/tools/run_net.py --cfg /workspace/thesis-ws/uniformerv2/exp/ego4d_hands/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab63420c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations  cropped_videos_ant\r\n"
     ]
    }
   ],
   "source": [
    "!ls /workspace/ego4d_data_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1a381",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
